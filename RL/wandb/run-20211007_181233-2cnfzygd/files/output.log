Total T: 12 Episode Num: 1 Episode T: 12 Reward: 12.000
Total T: 26 Episode Num: 2 Episode T: 14 Reward: 14.000
Total T: 41 Episode Num: 3 Episode T: 15 Reward: 15.000
Total T: 51 Episode Num: 4 Episode T: 10 Reward: 10.000
Total T: 66 Episode Num: 5 Episode T: 15 Reward: 15.000
Total T: 78 Episode Num: 6 Episode T: 12 Reward: 12.000
Total T: 89 Episode Num: 7 Episode T: 11 Reward: 11.000
Total T: 102 Episode Num: 8 Episode T: 13 Reward: 13.000
Total T: 115 Episode Num: 9 Episode T: 13 Reward: 13.000
Total T: 127 Episode Num: 10 Episode T: 12 Reward: 12.000
Total T: 143 Episode Num: 11 Episode T: 16 Reward: 16.000
Total T: 153 Episode Num: 12 Episode T: 10 Reward: 10.000
Total T: 167 Episode Num: 13 Episode T: 14 Reward: 14.000
Total T: 180 Episode Num: 14 Episode T: 13 Reward: 13.000
Total T: 190 Episode Num: 15 Episode T: 10 Reward: 10.000
Total T: 204 Episode Num: 16 Episode T: 14 Reward: 14.000
Total T: 215 Episode Num: 17 Episode T: 11 Reward: 11.000
Total T: 229 Episode Num: 18 Episode T: 14 Reward: 14.000
Total T: 242 Episode Num: 19 Episode T: 13 Reward: 13.000
Total T: 253 Episode Num: 20 Episode T: 11 Reward: 11.000
Total T: 269 Episode Num: 21 Episode T: 16 Reward: 16.000
Total T: 282 Episode Num: 22 Episode T: 13 Reward: 13.000
Total T: 296 Episode Num: 23 Episode T: 14 Reward: 14.000
Total T: 308 Episode Num: 24 Episode T: 12 Reward: 12.000
Total T: 321 Episode Num: 25 Episode T: 13 Reward: 13.000
Traceback (most recent call last):
  File "gym_train.py", line 211, in <module>
    args.eval_freq
  File "gym_train.py", line 69, in train
    action = from_torch(policy.select_action(to_torch(state, torch.float32)))
  File "/Users/kiranganeshan/reading-group/RL/util.py", line 28, in to_torch
    return torch.tensor(tensor, dtype=dtype)
KeyboardInterrupt