Traceback (most recent call last):
  File "gym_train.py", line 211, in <module>
    args.eval_freq
  File "gym_train.py", line 86, in train
    metrics = policy.train(*replay_buffer.sample(batch_size))
  File "/Users/kiranganeshan/reading-group/RL/PG/pg.py", line 52, in train
    loss = -torch.sum(torch.mean(qval * policy[:, action], dim=0))
KeyboardInterrupt
Total T: 12 Episode Num: 1 Episode T: 12 Reward: 12.000
Total T: 26 Episode Num: 2 Episode T: 14 Reward: 14.000
Total T: 41 Episode Num: 3 Episode T: 15 Reward: 15.000
Total T: 51 Episode Num: 4 Episode T: 10 Reward: 10.000
Total T: 66 Episode Num: 5 Episode T: 15 Reward: 15.000
Total T: 78 Episode Num: 6 Episode T: 12 Reward: 12.000
Total T: 89 Episode Num: 7 Episode T: 11 Reward: 11.000
Total T: 102 Episode Num: 8 Episode T: 13 Reward: 13.000
Total T: 115 Episode Num: 9 Episode T: 13 Reward: 13.000
Total T: 127 Episode Num: 10 Episode T: 12 Reward: 12.000
Total T: 143 Episode Num: 11 Episode T: 16 Reward: 16.000
Total T: 153 Episode Num: 12 Episode T: 10 Reward: 10.000
Total T: 167 Episode Num: 13 Episode T: 14 Reward: 14.000
Total T: 180 Episode Num: 14 Episode T: 13 Reward: 13.000