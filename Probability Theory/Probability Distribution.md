
## Introduction
We would like to discuss the likelihood of random events, or more precisely, stochastic events. (The word "random" invokes images of rolling dice, where there is an equal likelihood of all outcomes; we use the word "stochastic" to refer to the situation where not all outcomes have equal likelihood. In particular, both random and deterministic systems are stochastic: the random systems have an equal likelihood of all outcomes, whereas the deterministic systems have likelihood 1 on the outcomes that will certainly happen, and 0 otherwise. So "stochastic" captures random, deterministic, and everything in-between.) There are three reasons we care about modeling stochastic events:
1. Some events are fundamentally stochastic. For example, quantum mechanics indicates that the measured spin-state of an electron is fundamentally stochastic. More generally, there is fundamental stochasticity in the dynamics of small objects.
2. Deterministic systems appear stochastic when we cannot observe all variables driving system behavior. For example, if a deck of cards is shuffled behind a curtain, we cannot witness the shuffling order, and the order in which cards are drawn will appear stochastic.
3. Deterministic systems are effectively stochastic if we cannot keep track of all variables driving system behavior. For example, if a deck of cards is shuffled many times in a visible position, keeping track of the order of cards requires perceiving fine details that unfold very quickly, as well as a large enough working memory to store the necessary information. This makes it practically impossible for a human to deduce the shuffling order. Therefore the order in which cards are drawn will appear stochastic.

The framework used to reason about stochastic events is that of probability. We define the **sample space** $\Omega$ as the set of all possible outcomes for the system being discussed ($\Omega$ can be discrete or continuous). An **outcome** $\omega\in\Omega$ is a specific world-state resulting from the stochastic process; we don't necessarily observe the entire outcome, since not all parts of an outcome need to be measurable. We postulate that each of these outcomes has a **probability** $P(\omega)$ measuring its likelihood. Any part of the system we can measure is captured via a **random variable** denoted by a capital letter, e.g. $X$. This variable will take different values $X_{\omega}$ depending on the outcome $\omega$. We can define the **probability distribution** of the random variable as $$P(X = x) = \sum_{\omega\in\Omega} P(\omega) \mathbb{1}(X_{\omega} = x)$$(Note: the sum becomes an integral when $\Omega$ is continuous.) Since we only ever measure random variables, and not outcomes, from here onwards we only discuss the probability distribution of random variables. The sample-spaced-based definition, however, helps clarify how probability may be defined in terms of the world-state, at least in use cases (2) and (3).

## Definition
The **probability distribution** of a random variable $X$ defines the likelihood that $X$ will take any value in its range of possibility. For a discrete random variable $X$, with the range of values $\{x_i\}$, this is given by a **probability mass function (PMF)** $P_X(x_i)$. This function indicates that there is a probability $P_X(x_i)$ of observing the value $x_i$ for the variable $X$. PMFs are defined by the axioms $0\leq P_X(x_i)\leq 1$, and $\sum_i P_X(x_i) = 1$. Any function satisfying these axioms is a PMF over values $\{x_i\}$. (When obvious from context, we omit the subscript $X$: $P(x_i)$.) For a continuous random variable $X$, with a continuous range of values over the real numbers $\mathbb R$, the distribution is defined by a **probability density function (PDF)** $P_X(x)$. This function indicates that the probability of observing a value in the range $[x, x + \delta x]$ is $P_X(x)\delta x$ for very small $\delta x$. PDFs are defined by the axioms $P_X(x) \geq 0$ and $\int_{-\infty}^{\infty} P_X(x)dx = 1$. Any function satisfying these axioms is a PDF over $\mathbb R$. We can also define continuous random variables over other domains, including subsets of $\mathbb R$ (by setting the PDF to zero outside the subset), or larger spaces like $\mathbb R^n$ (by replacing $dx$ by the volume element $dx^n$). When $X$ is distributed according to a PMF or PDF $P_X$, we write $X\sim P_X$.